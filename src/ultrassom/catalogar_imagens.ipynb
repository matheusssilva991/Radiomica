{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gerar databases Ultrassom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configurações necessários"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io \n",
    "from scipy.signal import hilbert\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import urllib.request\n",
    "import cv2 as cv\n",
    "import sys, os\n",
    "\n",
    "sys.path.insert(0, \"\\\\\".join(os.path.abspath(os.curdir).split(\"\\\\\")[:-2:]))\n",
    "\n",
    "from src.utils.utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download images\n",
    "def download_imgs(urllink, tgt_path, names):\n",
    "    print('images saved to {}.'.format(tgt_path))\n",
    "    \n",
    "    for i, img_url in enumerate(urllink.values ):\n",
    "        filename = '\\\\{}.jpg'.format(names[i])\n",
    "        full_tgt_path = '{}{}'.format(tgt_path, filename)\n",
    "        urllib.request.urlretrieve(img_url, full_tgt_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. OASBUD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"D:\\\\mathe\\\\Documents\\\\BancoDados_IC\\\\Ultrassom\"\n",
    "data = scipy.io.loadmat(path + '\\\\OASBUD.mat')\n",
    "\n",
    "# Definir as variáveis\n",
    "c = 1540  # Velocidade do som em m/s (1540 m/s)\n",
    "width = 38  # Largura da abertura em mm (38 mm)\n",
    "fs = 40e6  # Frequência de amostragem em Hz (40 MHz)\n",
    "\n",
    "metadata = {'id': [], 'pathology': [], 'bi-rads': [], 'image_path': [], 'cropped_path': [], 'image_size_mb': []}\n",
    "\n",
    "for study in data['data'][0]:\n",
    "    i = 0\n",
    "    study_id = study[0][0]\n",
    "    folder_path = path + \"\\\\OASBUD\\\\\" + study_id\n",
    "    \n",
    "    # Criar a pasta para salvar as imagens\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.mkdir(folder_path)\n",
    "    \n",
    "    for rf, roi in zip([study[1], study[2]], [study[3], study[4]]):\n",
    "        metadata['patientId'].append(study_id)\n",
    "        metadata['biRads'].append(study[5][0][0])\n",
    "        metadata['pathology'].append(study[6][0][0])\n",
    "        \n",
    "        # Calcular os eixos z e y\n",
    "        rf_shape = rf.shape\n",
    "        z_axis = 1000 * np.linspace(0, rf_shape[0] * 0.5 * c / fs, rf_shape[0])  # Profundidade em mm\n",
    "        y_axis = np.linspace(0, width, rf_shape[1])  # Largura em mm\n",
    "\n",
    "        # Calcular a imagem de envelope\n",
    "        envelope_image = 20 * np.log10(np.abs(np.apply_along_axis(lambda x: hilbert(x), 0, rf)))\n",
    "        envelope_image = envelope_image * roi\n",
    "    \n",
    "        # Criar o gráfico de escala de cinza\n",
    "        im = plt.imshow(envelope_image, cmap='gray', extent=[y_axis[0], y_axis[-1], z_axis[-1], z_axis[0]])\n",
    "        cbar = plt.colorbar(im)\n",
    "        cbar.remove()  # Remove a barra de cores\n",
    "        plt.clim(40, 80)  # Define o intervalo de cores\n",
    "        \n",
    "        # Remover os rótulos dos eixos x e y\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        \n",
    "        # Salva a imagem original\n",
    "        plt.savefig(f'{folder_path}\\\\{study_id}_{i}.png', bbox_inches='tight', pad_inches=0)\n",
    "        metadata['imagePath'].append(f'{folder_path}\\\\{study_id}_{i}.png')\n",
    "        metadata['imageSizeMb'].append(get_images_size(f'{folder_path}\\\\{study_id}_{i}.png', \"png\", False))\n",
    "        \n",
    "        # salva a imagem com a ROI\n",
    "        envelope_image = envelope_image * roi\n",
    "        im = plt.imshow(envelope_image, cmap='gray', extent=[y_axis[0], y_axis[-1], z_axis[-1], z_axis[0]])\n",
    "        plt.savefig(f'{folder_path}\\\\{study_id}_{i}_roi.png', bbox_inches='tight', pad_inches=0)\n",
    "        metadata['croppedImagePath'].append(f'{folder_path}\\\\{study_id}_{i}_roi.png')\n",
    "        \n",
    "        i += 1\n",
    "              \n",
    "df = pd.DataFrame(metadata)\n",
    "df['pathology'] = df['pathology'].map({0: 'Benign', 1: 'Malignant'})\n",
    "df.to_csv(path + \"\\\\OASBUD_metadata.csv\", index=False)\n",
    "df.to_csv(\"../../outputs/ultrassom/OASBUD_metadata.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. HMSS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configurações inciais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"D:\\\\mathe\\\\Documents\\\\BancoDados_IC\\\\Ultrassom\"\n",
    "tgt_path = path + \"\\\\HMSS\"\n",
    "\n",
    "if not os.path.exists(tgt_path):\n",
    "    os.mkdir(tgt_path)\n",
    "\n",
    "ds = pd.read_csv(\"../../data/ultrassom/HMSS/HMSS_raw.csv\" ) # change back to HMSS.csv at the end\n",
    "ROOT = 'https://www.ultrasoundcases.info'\n",
    "#urllinkcover = ROOT+url.casecoverimage\n",
    "urllinkimage = ROOT + ds['img url']\n",
    "\n",
    "#CaseCoverName = url.CaseCoverName\n",
    "img_names = ds['img name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baixar as imagens, recortar e salvar os metadados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cropping images\n",
    "def cropping_Images(ds, src_path, names, tgt_path):\n",
    "    '''\n",
    "    '''\n",
    "    rw1 = ds['crop r1']  # top bound\n",
    "    rw2 = ds['crop r2']  # bottom bound\n",
    "    cl1 = ds['crop col1']  # left bound\n",
    "    cl2 = ds['crop col2']  # right bound\n",
    "\n",
    "    for i, name in enumerate(names):\n",
    "        r1 = rw1[i]\n",
    "        r2 = rw2[i]+r1\n",
    "        c1 = cl1[i]\n",
    "        c2 = cl2[i]+c1\n",
    "\n",
    "        tmp_img = cv.imread(Path.join(src_path, str(name)+'.jpg'))\n",
    "        img = tmp_img[r1:r2, c1:c2]\n",
    "\n",
    "        cv.imwrite(Path.join(tgt_path, str(name)+'.jpg'), img)\n",
    "        print(i, 'crop ', str(name)+'.jpg', tmp_img.shape,\n",
    "              '-->', img.shape, str(name)+'.jpg')\n",
    "\n",
    "#sendLinks(urllink, PathImages, imagenames)\n",
    "download_imgs(urllinkimage, tgt_path, img_names)\n",
    "# cropping images(dataset, source path, image names, target path)\n",
    "cropping_Images(ds, tgt_path, img_names, tgt_path)\n",
    "\n",
    "# Salvar os metadados\n",
    "metadata_csv = ds[['img name', 'group', 'subgroup', 'subgroup url', 'case description', 'img url']].copy()\n",
    "metadata_csv.loc[:, 'image_path'] = f'{tgt_path}\\\\' + metadata_csv['img name'] + '.jpg'\n",
    "metadata_csv['pathology'] = ds['tumor type'].capitalize()\n",
    "metadata_csv.rename(columns={'img name': 'patientId', 'subgroup url': 'subgroupUrl', 'img url': 'imgUrl', \n",
    "                             'case description': 'caseDescription', }, inplace=True)\n",
    "\n",
    "images_size = get_images_size(\"D:\\\\mathe\\\\Documents\\\\BancoDados_IC\\\\Ultrassom\\\\HMSS\", \"jpg\", True)\n",
    "metadata_csv['imageSizeMb'] = images_size\n",
    "\n",
    "metadata_csv.to_csv(path + \"\\\\HMSS_metadata.csv\", index=False)\n",
    "metadata_csv.to_csv(\"../../outputs/ultrassom/HMSS_metadata.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Thammasat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configurações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading csv file and parsing columns\n",
    "path = \"D:\\\\mathe\\\\Documents\\\\BancoDados_IC\\\\Ultrassom\"\n",
    "tgt_path = path + \"\\\\Thammasat\"\n",
    "\n",
    "if not os.path.exists(tgt_path):\n",
    "    os.mkdir(tgt_path)\n",
    "\n",
    "ds = pd.read_csv(\"../../data/ultrassom/THAMMASAT/Thammasat_raw.csv\" ) # change back to HMSS.csv at the end\")\n",
    "\n",
    "urls = ds['img url']\n",
    "img_names = ds['img name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baixar, recortar as imagens e salvar os metadados "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cropping_Images(ds, src_path, names, tgt_path):\n",
    "    '''\n",
    "    '''\n",
    "    rw1 = ds['crop r1'] # top bound\n",
    "    rw2 = ds['crop r2'] # bottom bound\n",
    "    cl1 = ds['crop col1'] # left bound\n",
    "    cl2 = ds['crop col2'] # right bound\n",
    "    \n",
    "    for i, name in enumerate(names):\n",
    "        r1 = rw1[i]-1\n",
    "        r2 = rw2[i]-1\n",
    "        c1 = cl1[i]-1\n",
    "        c2 = cl2[i]-1\n",
    "        \n",
    "        tmp_img = cv.imread(Path.join(src_path,name+'.jpg'))\n",
    "        img = tmp_img[r1:r2,c1:c2]\n",
    "        \n",
    "        cv.imwrite(Path.join(tgt_path, name+'.jpg'), img)\n",
    "        print(i, 'crop ', name+'.jpg', tmp_img.shape, '-->', img.shape, name+'.jpg')\n",
    "\n",
    "#sendLinks(urllink, PathImages, imagenames)\n",
    "download_imgs(urls, tgt_path, img_names)\n",
    "# cropping images(dataset, source path, image names, target path)\n",
    "cropping_Images(ds, tgt_path, img_names, tgt_path)\n",
    "\n",
    "# Salvar os metadados\n",
    "metadata_csv = ds[['img name', 'img url']].copy()\n",
    "metadata_csv.loc[:, 'image_path'] = f'{tgt_path}\\\\' + metadata_csv['img name'] + '.jpg'\n",
    "metadata_csv['pathology'] = ds['tumor type']\n",
    "metadata_csv.rename(columns={'img name': 'patientId', 'img url': 'imgUrl', 'image_path': 'imagePath'}, inplace=True)\n",
    "\n",
    "images_size = get_images_size(\"D:\\\\mathe\\\\Documents\\\\BancoDados_IC\\\\Ultrassom\\\\THAMMASAT\", \"jpg\", True)\n",
    "metadata_csv['imageSizeMb'] = images_size\n",
    "metadata_csv['pathology'] = metadata_csv['pathology'].str.capitalize()\n",
    "\n",
    "metadata_csv.to_csv(path + \"\\\\THAMMASAT_metadata.csv\", index=False)\n",
    "metadata_csv.to_csv(\"../../outputs/ultrassom/THAMMASAT_metadata.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. BUSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "benign: 437\n",
      "benign_mask: 454\n",
      "malignant: 210\n",
      "malignant_mask: 211\n",
      "normal: 133\n",
      "normal_mask: 133\n"
     ]
    }
   ],
   "source": [
    "path_dataset = \"D:\\\\mathe\\\\Documents\\\\BancoDados_IC\\\\Ultrassom\\\\Dataset_BUSI_with_GT\"\n",
    "folders = ['benign', 'malignant', 'normal']\n",
    "dict_count_pathology = {}\n",
    "dict_pathology = []\n",
    "\n",
    "for pathology in folders:\n",
    "    path = path_dataset + f\"\\{pathology}\"\n",
    "    \n",
    "    original = [img for img in os.listdir(path) if \"mask\" not in img]\n",
    "    cropped = [img for img in os.listdir(path) if \"mask\" in img]\n",
    "    \n",
    "    dict_count_pathology[f'{pathology}'] = len(original)\n",
    "    dict_count_pathology[f'{pathology}_mask'] = len(cropped)\n",
    "    \n",
    "    for img_name, cropp_name in zip(original, cropped):\n",
    "        study = {'patientId': img_name.replace(\".png\", \"\").replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\"), \n",
    "                 'imagePath': path + f\"\\{img_name}\",\n",
    "                 'croppedImagePath': path + f\"\\{cropp_name}\",\n",
    "                 'pathology': pathology.capitalize(),\n",
    "                 'imageSizeMb': get_images_size(path + f\"\\{img_name}\", \"png\", False)}\n",
    "        \n",
    "        dict_pathology.append(study)\n",
    "        \n",
    "metadata_csv = pd.DataFrame(dict_pathology)\n",
    "metadata_csv.to_csv(\"../../outputs/ultrassom/BUSI_metadata.csv\", index=False)\n",
    "        \n",
    "for key, value in dict_count_pathology.items():\n",
    "    print(f\"{key}: {value}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Ultrasound breast dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benign: 4574\n",
      "Malignant: 4442\n"
     ]
    }
   ],
   "source": [
    "path_dataset = \"D:\\\\mathe\\\\Documents\\\\BancoDados_IC\\\\Ultrassom\\\\ultrasound_breast_classification\"\n",
    "dict_pathology = []\n",
    "\n",
    "for part in ['train', 'val']:\n",
    "    for pathology in ['benign', 'malignant']:\n",
    "        path = path_dataset + f'\\{part}\\{pathology}'\n",
    "        \n",
    "        images = os.listdir(path)\n",
    "        \n",
    "        for img_name in images:\n",
    "            study = {'patientId': img_name.replace(\".png\", \"\").replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\"), \n",
    "                 'imagePath': path + f\"\\{img_name}\",\n",
    "                 'pathology': pathology.capitalize(),\n",
    "                 'imageSizeMb': get_images_size(path + f\"\\{img_name}\", \"png\", False)}\n",
    "            \n",
    "            dict_pathology.append(study)\n",
    "\n",
    "metadata_csv = pd.DataFrame(dict_pathology)\n",
    "metadata_csv.to_csv(\"../../outputs/ultrassom/UBC_metadata.csv\", index=False)\n",
    "metadata_csv.to_csv(\"D:\\\\mathe\\\\Documents\\\\BancoDados_IC\\\\Ultrassom\\\\UBC_metadata.csv\", index=False)\n",
    "\n",
    "print(f\"Benign: {metadata_csv[metadata_csv['pathology'] == 'Benign'].shape[0]}\")\n",
    "print(f\"Malignant: {metadata_csv[metadata_csv['pathology'] == 'Malignant'].shape[0]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "radiomica",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
