{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.models import Sequential\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sys.path.insert(0, \"\\\\\".join(os.path.abspath(os.curdir).split(\"\\\\\")[:-2:]))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from src.utils.utils import *\n",
    "\n",
    "# from keras.wrappers.scikit_learn import KerasClassifier\n",
    "# from sklearn.model_selection import GridSearchCV, RandomizedSearchCV"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos preditivo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuração"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECTED_DATABASE = \"MIAS\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importação e análise dos conjuntos de dados"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iniciamos importando o conjunto de dados e realizamos a visualização das 5 primeiras linhas para verificar a estrutura dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dissimilarity_ang_0_dist_1</th>\n",
       "      <th>dissimilarity_ang_45_dist_1</th>\n",
       "      <th>dissimilarity_ang_90_dist_1</th>\n",
       "      <th>dissimilarity_ang_135_dist_1</th>\n",
       "      <th>dissimilarity_ang_0_dist_3</th>\n",
       "      <th>dissimilarity_ang_45_dist_3</th>\n",
       "      <th>dissimilarity_ang_90_dist_3</th>\n",
       "      <th>dissimilarity_ang_135_dist_3</th>\n",
       "      <th>correlation_ang_0_dist_1</th>\n",
       "      <th>correlation_ang_45_dist_1</th>\n",
       "      <th>...</th>\n",
       "      <th>energy_ang_0_dist_1</th>\n",
       "      <th>energy_ang_45_dist_1</th>\n",
       "      <th>energy_ang_90_dist_1</th>\n",
       "      <th>energy_ang_135_dist_1</th>\n",
       "      <th>energy_ang_0_dist_3</th>\n",
       "      <th>energy_ang_45_dist_3</th>\n",
       "      <th>energy_ang_90_dist_3</th>\n",
       "      <th>energy_ang_135_dist_3</th>\n",
       "      <th>pathology</th>\n",
       "      <th>image_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.743480</td>\n",
       "      <td>0.938587</td>\n",
       "      <td>0.638144</td>\n",
       "      <td>0.879220</td>\n",
       "      <td>1.493057</td>\n",
       "      <td>1.409452</td>\n",
       "      <td>1.165028</td>\n",
       "      <td>1.319702</td>\n",
       "      <td>0.998509</td>\n",
       "      <td>0.997434</td>\n",
       "      <td>...</td>\n",
       "      <td>0.577150</td>\n",
       "      <td>0.576423</td>\n",
       "      <td>0.579305</td>\n",
       "      <td>0.576354</td>\n",
       "      <td>0.574213</td>\n",
       "      <td>0.574944</td>\n",
       "      <td>0.577854</td>\n",
       "      <td>0.574892</td>\n",
       "      <td>Benign</td>\n",
       "      <td>D:/mathe/Documents/BancoDados_IC/Mamografia/MI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.126747</td>\n",
       "      <td>1.393149</td>\n",
       "      <td>0.968634</td>\n",
       "      <td>1.413172</td>\n",
       "      <td>2.277286</td>\n",
       "      <td>2.194972</td>\n",
       "      <td>1.922073</td>\n",
       "      <td>2.213473</td>\n",
       "      <td>0.997826</td>\n",
       "      <td>0.997085</td>\n",
       "      <td>...</td>\n",
       "      <td>0.488012</td>\n",
       "      <td>0.487575</td>\n",
       "      <td>0.492359</td>\n",
       "      <td>0.487658</td>\n",
       "      <td>0.484513</td>\n",
       "      <td>0.485373</td>\n",
       "      <td>0.488980</td>\n",
       "      <td>0.485563</td>\n",
       "      <td>Benign</td>\n",
       "      <td>D:/mathe/Documents/BancoDados_IC/Mamografia/MI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.119408</td>\n",
       "      <td>1.431990</td>\n",
       "      <td>1.016493</td>\n",
       "      <td>1.366212</td>\n",
       "      <td>2.148667</td>\n",
       "      <td>2.087481</td>\n",
       "      <td>1.669776</td>\n",
       "      <td>1.973510</td>\n",
       "      <td>0.997504</td>\n",
       "      <td>0.996087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.410421</td>\n",
       "      <td>0.409889</td>\n",
       "      <td>0.411775</td>\n",
       "      <td>0.409951</td>\n",
       "      <td>0.407030</td>\n",
       "      <td>0.408066</td>\n",
       "      <td>0.411030</td>\n",
       "      <td>0.408270</td>\n",
       "      <td>Benign</td>\n",
       "      <td>D:/mathe/Documents/BancoDados_IC/Mamografia/MI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.119408</td>\n",
       "      <td>1.431990</td>\n",
       "      <td>1.016493</td>\n",
       "      <td>1.366212</td>\n",
       "      <td>2.148667</td>\n",
       "      <td>2.087481</td>\n",
       "      <td>1.669776</td>\n",
       "      <td>1.973510</td>\n",
       "      <td>0.997504</td>\n",
       "      <td>0.996087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.410421</td>\n",
       "      <td>0.409889</td>\n",
       "      <td>0.411775</td>\n",
       "      <td>0.409951</td>\n",
       "      <td>0.407030</td>\n",
       "      <td>0.408066</td>\n",
       "      <td>0.411030</td>\n",
       "      <td>0.408270</td>\n",
       "      <td>Benign</td>\n",
       "      <td>D:/mathe/Documents/BancoDados_IC/Mamografia/MI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.831069</td>\n",
       "      <td>0.954908</td>\n",
       "      <td>0.668050</td>\n",
       "      <td>1.010285</td>\n",
       "      <td>1.671718</td>\n",
       "      <td>1.468367</td>\n",
       "      <td>1.242472</td>\n",
       "      <td>1.534555</td>\n",
       "      <td>0.997882</td>\n",
       "      <td>0.997707</td>\n",
       "      <td>...</td>\n",
       "      <td>0.586297</td>\n",
       "      <td>0.586001</td>\n",
       "      <td>0.588736</td>\n",
       "      <td>0.586033</td>\n",
       "      <td>0.583368</td>\n",
       "      <td>0.584126</td>\n",
       "      <td>0.586787</td>\n",
       "      <td>0.584278</td>\n",
       "      <td>Benign</td>\n",
       "      <td>D:/mathe/Documents/BancoDados_IC/Mamografia/MI...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   dissimilarity_ang_0_dist_1  dissimilarity_ang_45_dist_1  \\\n",
       "0                    0.743480                     0.938587   \n",
       "1                    1.126747                     1.393149   \n",
       "2                    1.119408                     1.431990   \n",
       "3                    1.119408                     1.431990   \n",
       "4                    0.831069                     0.954908   \n",
       "\n",
       "   dissimilarity_ang_90_dist_1  dissimilarity_ang_135_dist_1  \\\n",
       "0                     0.638144                      0.879220   \n",
       "1                     0.968634                      1.413172   \n",
       "2                     1.016493                      1.366212   \n",
       "3                     1.016493                      1.366212   \n",
       "4                     0.668050                      1.010285   \n",
       "\n",
       "   dissimilarity_ang_0_dist_3  dissimilarity_ang_45_dist_3  \\\n",
       "0                    1.493057                     1.409452   \n",
       "1                    2.277286                     2.194972   \n",
       "2                    2.148667                     2.087481   \n",
       "3                    2.148667                     2.087481   \n",
       "4                    1.671718                     1.468367   \n",
       "\n",
       "   dissimilarity_ang_90_dist_3  dissimilarity_ang_135_dist_3  \\\n",
       "0                     1.165028                      1.319702   \n",
       "1                     1.922073                      2.213473   \n",
       "2                     1.669776                      1.973510   \n",
       "3                     1.669776                      1.973510   \n",
       "4                     1.242472                      1.534555   \n",
       "\n",
       "   correlation_ang_0_dist_1  correlation_ang_45_dist_1  ...  \\\n",
       "0                  0.998509                   0.997434  ...   \n",
       "1                  0.997826                   0.997085  ...   \n",
       "2                  0.997504                   0.996087  ...   \n",
       "3                  0.997504                   0.996087  ...   \n",
       "4                  0.997882                   0.997707  ...   \n",
       "\n",
       "   energy_ang_0_dist_1  energy_ang_45_dist_1  energy_ang_90_dist_1  \\\n",
       "0             0.577150              0.576423              0.579305   \n",
       "1             0.488012              0.487575              0.492359   \n",
       "2             0.410421              0.409889              0.411775   \n",
       "3             0.410421              0.409889              0.411775   \n",
       "4             0.586297              0.586001              0.588736   \n",
       "\n",
       "   energy_ang_135_dist_1  energy_ang_0_dist_3  energy_ang_45_dist_3  \\\n",
       "0               0.576354             0.574213              0.574944   \n",
       "1               0.487658             0.484513              0.485373   \n",
       "2               0.409951             0.407030              0.408066   \n",
       "3               0.409951             0.407030              0.408066   \n",
       "4               0.586033             0.583368              0.584126   \n",
       "\n",
       "   energy_ang_90_dist_3  energy_ang_135_dist_3  pathology  \\\n",
       "0              0.577854               0.574892     Benign   \n",
       "1              0.488980               0.485563     Benign   \n",
       "2              0.411030               0.408270     Benign   \n",
       "3              0.411030               0.408270     Benign   \n",
       "4              0.586787               0.584278     Benign   \n",
       "\n",
       "                                          image_path  \n",
       "0  D:/mathe/Documents/BancoDados_IC/Mamografia/MI...  \n",
       "1  D:/mathe/Documents/BancoDados_IC/Mamografia/MI...  \n",
       "2  D:/mathe/Documents/BancoDados_IC/Mamografia/MI...  \n",
       "3  D:/mathe/Documents/BancoDados_IC/Mamografia/MI...  \n",
       "4  D:/mathe/Documents/BancoDados_IC/Mamografia/MI...  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breast_cancer_df = None\n",
    "\n",
    "match SELECTED_DATABASE:\n",
    "    case \"CMMD\":\n",
    "        breast_cancer_df = pd.read_csv(\"../../outputs/mamografia/matriz_glcm_features/matriz_features_glcm_CMMD.csv\")\n",
    "    case \"CBIS-DDSM\":\n",
    "        breast_cancer_df = pd.read_csv(\"../../outputs/mamografia/matriz_glcm_features/matriz_features_glcm_CBIS-DDSM.csv\")\n",
    "    case \"INBREAST\":\n",
    "        breast_cancer_df = pd.read_csv(\"../../outputs/mamografia/matriz_glcm_features/matriz_features_glcm_INBREAST.csv\")\n",
    "    case \"MIAS\":\n",
    "        breast_cancer_df = pd.read_csv(\"../../outputs/mamografia/matriz_glcm_features/matriz_features_glcm_MIAS.csv\")\n",
    "    case _:\n",
    "        raise Exception(\"Database not found!\")\n",
    "    \n",
    "breast_cancer_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como último passo, verificamos a distribuição das classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Benign       0.561983\n",
       "Malignant    0.438017\n",
       "Name: pathology, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breast_cancer_df[\"pathology\"].value_counts(normalize=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pré-Processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elimina os dados com classe BENIGN_WITHOUT_CALLBACK ou NORMAL\n",
    "if SELECTED_DATABASE == \"CBIS-DDSM\":\n",
    "    breast_cancer_df = breast_cancer_df[breast_cancer_df[\"pathology\"] != \"BENIGN_WITHOUT_CALLBACK\"]\n",
    "elif SELECTED_DATABASE == \"INBREAST\":\n",
    "    breast_cancer_df = breast_cancer_df[breast_cancer_df[\"pathology\"] != \"NORMAL\"]\n",
    "\n",
    "# Separa em features e labels\n",
    "X, y = (breast_cancer_df.drop(\"pathology\", axis=1), breast_cancer_df[\"pathology\"])\n",
    "\n",
    "# Balanceamento de classes\n",
    "if SELECTED_DATABASE == \"CMMD\":\n",
    "    nm = NearMiss(version=1)\n",
    "    X, y = nm.fit_resample(X, y)\n",
    "elif SELECTED_DATABASE == \"INBREAST\":\n",
    "    smote = SMOTE()\n",
    "    X, y = smote.fit_resample(X, y)\n",
    "\n",
    "# Separa os dados em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)\n",
    "\n",
    "# Salva e retira image_path\n",
    "image_paths_train = X_train[\"image_path\"]\n",
    "image_paths_test = X_test[\"image_path\"]\n",
    "X_train = X_train.drop(\"image_path\", axis=1)\n",
    "X_test = X_test.drop(\"image_path\", axis=1)\n",
    "\n",
    " # Padroniza os dados\n",
    "\"\"\" columns = X_train.columns\n",
    "scaler = StandardScaler()\n",
    "X_train = pd.DataFrame(scaler.fit_transform(X_train), columns=columns)\n",
    "X_test = pd.DataFrame(scaler.transform(X_test), columns=columns) \"\"\"\n",
    "\n",
    "# Tratamos os rótulos categóricos\n",
    "if SELECTED_DATABASE == \"CMMD\" or \"MIAS\":\n",
    "    y_train = y_train.map({\"Benign\": 0, \"Malignant\": 1})\n",
    "    y_test = y_test.map({\"Benign\": 0, \"Malignant\": 1})\n",
    "elif SELECTED_DATABASE == 'CBIS-DDSM' or 'INBREAST':\n",
    "    y_train = y_train.map({\"BENIGN\": 0, \"MALIGNANT\": 1})\n",
    "    y_test = y_test.map({\"BENIGN\": 0, \"MALIGNANT\": 1})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento dos modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "angles = [\"0\", \"45\", \"90\", \"135\"]\n",
    "distances = ['1', '3']\n",
    "threshold = 0.5 # Definir o limiar\n",
    "kf = KFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para criar o modelo do Keras\n",
    "def create_mlp_model(shape):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(50, input_dim=shape, activation=\"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(50, activation=\"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\", metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "\n",
    "def evaluate_mlp_model(model, data, target, n_splits, n_epochs, batch_size, threshold=0.5):\n",
    "    kf = KFold(n_splits = n_splits)\n",
    "    \n",
    "    acc = []\n",
    "    for train_index, test_index in kf.split(data, target): \n",
    "        model.fit(data.iloc[train_index], target.iloc[train_index], \n",
    "                  epochs=n_epochs, batch_size=batch_size)\n",
    "        \n",
    "        y_pred = model.predict(data.iloc[test_index])\n",
    "        \n",
    "        # Definir o limiar\n",
    "        threshold = threshold\n",
    "\n",
    "        # Transformar as saídas em rótulos\n",
    "        y_pred = (y_pred > threshold).astype(int)\n",
    "        \n",
    "        acc.append(accuracy_score(y_pred, target.iloc[test_index]))\n",
    "\n",
    "    return (np.array(acc)).mean() * 100"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' for distance in distances:\\n    for angle in angles:\\n        columns = [column for column in X_test.columns if f\"ang_{angle}_dist_{distance}\" in column]\\n        X_train_filtered = X_train.loc[::, columns]\\n        X_test_filtered = X_test.loc[::, columns]\\n\\n        knn_model = KNeighborsClassifier(n_neighbors=5, weights=\"distance\", metric=\"euclidean\", algorithm=\"auto\")\\n        # knn_model.fit(X_train_filtered, y_train)\\n        # predict = knn_model.predict(X_test_filtered)\\n        # acurracy = accuracy_score(y_test, predict) * 100\\n        acurracy = (cross_val_score(knn_model, X_test_filtered, y_test, cv=kf).mean()) * 100\\n\\n        #predicts[\"KNeighborsClassifier\"][f\"ang_{angle}_dist_{distance}\"] = predict\\n        scores[\"KNeighborsClassifier\"][f\"ang_{angle}_dist_{distance}\"] = {\"accuracy_score\": acurracy} '"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Treina com todos os angulos e distancias\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5, weights=\"distance\", metric=\"euclidean\", algorithm=\"auto\")\n",
    "\n",
    "knn_model.fit(X_train, y_train)\n",
    "predict = knn_model.predict(X_test)\n",
    "acurracy = accuracy_score(y_test, predict) * 100\n",
    "#acurracy = (cross_val_score(knn_model, X_test, y_test, cv=kf).mean()) * 100\n",
    "\n",
    "# predicts = {\"KNeighborsClassifier\": {\"all\": predict}}\n",
    "scores = {\"KNeighborsClassifier\": {\"all\": {\"accuracy_score\": acurracy}}}\n",
    "\n",
    "\"\"\" for distance in distances:\n",
    "    for angle in angles:\n",
    "        columns = [column for column in X_test.columns if f\"ang_{angle}_dist_{distance}\" in column]\n",
    "        X_train_filtered = X_train.loc[::, columns]\n",
    "        X_test_filtered = X_test.loc[::, columns]\n",
    "\n",
    "        knn_model = KNeighborsClassifier(n_neighbors=5, weights=\"distance\", metric=\"euclidean\", algorithm=\"auto\")\n",
    "        # knn_model.fit(X_train_filtered, y_train)\n",
    "        # predict = knn_model.predict(X_test_filtered)\n",
    "        # acurracy = accuracy_score(y_test, predict) * 100\n",
    "        acurracy = (cross_val_score(knn_model, X_test_filtered, y_test, cv=kf).mean()) * 100\n",
    "\n",
    "        #predicts[\"KNeighborsClassifier\"][f\"ang_{angle}_dist_{distance}\"] = predict\n",
    "        scores[\"KNeighborsClassifier\"][f\"ang_{angle}_dist_{distance}\"] = {\"accuracy_score\": acurracy} \"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' for distance in distances:\\n    for angle in angles:\\n        columns = [column for column in X_test.columns if f\"ang_{angle}_dist_{distance}\" in column]\\n        X_train_filtered = X_train.loc[::, columns]\\n        X_test_filtered = X_test.loc[::, columns]\\n        \\n        random_forest_model = RandomForestClassifier(n_estimators=200, max_depth=10, criterion=\"gini\", \\n                                                     min_samples_leaf=3, min_samples_split=2)\\n        \\n        # random_forest_model.fit(X_train_filtered, y_train)\\n        # predict = random_forest_model.predict(X_test_filtered)\\n        # acurracy = accuracy_score(y_test, predict) * 100\\n        acurracy = (cross_val_score(random_forest_model, X_test_filtered, y_test, cv=kf).mean()) * 100\\n\\n        # predicts[\"RandomForestClassifier\"][f\"ang_{angle}_dist_{distance}\"] = predict\\n        scores[\"RandomForestClassifier\"][f\"ang_{angle}_dist_{distance}\"] = {\"accuracy_score\": acurracy} '"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Treina com todos os angulos e distancias\n",
    "random_forest_model = RandomForestClassifier(n_estimators=200, max_depth=10, criterion=\"gini\", \n",
    "                                             min_samples_leaf=3, min_samples_split=2)\n",
    "random_forest_model.fit(X_train, y_train)\n",
    "predict = random_forest_model.predict(X_test)\n",
    "acurracy = accuracy_score(y_test, predict) * 100\n",
    "#acurracy = (cross_val_score(random_forest_model, X_test, y_test, cv=kf).mean()) * 100\n",
    "\n",
    "# predicts[\"RandomForestClassifier\"] = {\"all\": predict}\n",
    "scores[\"RandomForestClassifier\"] = {\"all\": {\"accuracy_score\": acurracy}}\n",
    "\n",
    "\"\"\" for distance in distances:\n",
    "    for angle in angles:\n",
    "        columns = [column for column in X_test.columns if f\"ang_{angle}_dist_{distance}\" in column]\n",
    "        X_train_filtered = X_train.loc[::, columns]\n",
    "        X_test_filtered = X_test.loc[::, columns]\n",
    "        \n",
    "        random_forest_model = RandomForestClassifier(n_estimators=200, max_depth=10, criterion=\"gini\", \n",
    "                                                     min_samples_leaf=3, min_samples_split=2)\n",
    "        \n",
    "        # random_forest_model.fit(X_train_filtered, y_train)\n",
    "        # predict = random_forest_model.predict(X_test_filtered)\n",
    "        # acurracy = accuracy_score(y_test, predict) * 100\n",
    "        acurracy = (cross_val_score(random_forest_model, X_test_filtered, y_test, cv=kf).mean()) * 100\n",
    "\n",
    "        # predicts[\"RandomForestClassifier\"][f\"ang_{angle}_dist_{distance}\"] = predict\n",
    "        scores[\"RandomForestClassifier\"][f\"ang_{angle}_dist_{distance}\"] = {\"accuracy_score\": acurracy} \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' for distance in distances:\\n    for angle in angles:\\n        columns = [column for column in X_test.columns if f\"ang_{angle}_dist_{distance}\" in column]\\n        X_train_filtered = X_train.loc[::, columns]\\n        X_test_filtered = X_test.loc[::, columns]\\n\\n        svm_model = svm.SVC(C=10, gamma=\\'scale\\', kernel=\\'linear\\')\\n        \\n        # svm_model.fit(X_train_filtered, y_train)\\n        # predict = svm_model.predict(X_test_filtered)\\n        # acurracy = accuracy_score(y_test, predict) * 100\\n        acurracy = (cross_val_score(svm_model, X_test_filtered, y_test, cv=kf).mean()) * 100\\n\\n        # predicts[\"SVM\"][f\"ang_{angle}_dist_{distance}\"] = predict\\n        scores[\"SVM\"][f\"ang_{angle}_dist_{distance}\"] = {\"accuracy_score\": acurracy} '"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Treina com todos os angulos e distancias\n",
    "svm_model = svm.SVC(C=10, gamma='scale', kernel='linear')\n",
    "svm_model.fit(X_train, y_train)\n",
    "predict = svm_model.predict(X_test)\n",
    "acurracy = accuracy_score(y_test, predict) * 100\n",
    "#acurracy = (cross_val_score(svm_model, X_test, y_test, cv=kf).mean()) * 100\n",
    "\n",
    "# predicts[\"SVM\"] = {\"all\": predict}\n",
    "scores[\"SVM\"] = {\"all\": {\"accuracy_score\": acurracy}}\n",
    "\n",
    "\"\"\" for distance in distances:\n",
    "    for angle in angles:\n",
    "        columns = [column for column in X_test.columns if f\"ang_{angle}_dist_{distance}\" in column]\n",
    "        X_train_filtered = X_train.loc[::, columns]\n",
    "        X_test_filtered = X_test.loc[::, columns]\n",
    "\n",
    "        svm_model = svm.SVC(C=10, gamma='scale', kernel='linear')\n",
    "        \n",
    "        # svm_model.fit(X_train_filtered, y_train)\n",
    "        # predict = svm_model.predict(X_test_filtered)\n",
    "        # acurracy = accuracy_score(y_test, predict) * 100\n",
    "        acurracy = (cross_val_score(svm_model, X_test_filtered, y_test, cv=kf).mean()) * 100\n",
    "\n",
    "        # predicts[\"SVM\"][f\"ang_{angle}_dist_{distance}\"] = predict\n",
    "        scores[\"SVM\"][f\"ang_{angle}_dist_{distance}\"] = {\"accuracy_score\": acurracy} \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boosted Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' for distance in distances:\\n    for angle in angles:\\n        columns = [column for column in X_test.columns if f\"ang_{angle}_dist_{distance}\" in column]\\n        X_train_filtered = X_train.loc[::, columns]\\n        X_test_filtered = X_test.loc[::, columns]\\n\\n        boosted_tree_model = GradientBoostingClassifier(learning_rate=0.1, max_depth=3, n_estimators=100)\\n        \\n        # boosted_tree_model.fit(X_train_filtered, y_train)\\n        # predict = boosted_tree_model.predict(X_test_filtered)\\n        # acurracy = accuracy_score(y_test, predict) * 100\\n        acurracy = (cross_val_score(boosted_tree_model, X_test_filtered, y_test, cv=kf).mean()) * 100\\n        \\n        # predicts[\"GradientBoostingClassifier\"][f\"ang_{angle}_dist_{distance}\"] = predict\\n        scores[\"GradientBoostingClassifier\"][f\"ang_{angle}_dist_{distance}\"] = {\"accuracy_score\": acurracy} '"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Treina com todos os angulos e distancias\n",
    "boosted_tree_model = GradientBoostingClassifier(learning_rate=0.1, max_depth=3, n_estimators=100)\n",
    "boosted_tree_model.fit(X_train, y_train)\n",
    "predict = boosted_tree_model.predict(X_test)\n",
    "acurracy = accuracy_score(y_test, predict) * 100\n",
    "#acurracy = (cross_val_score(boosted_tree_model, X_test, y_test, cv=kf).mean()) * 100\n",
    "\n",
    "# predicts[\"GradientBoostingClassifier\"] = {\"all\": predict}\n",
    "scores[\"GradientBoostingClassifier\"] = {\"all\": {\"accuracy_score\": acurracy}}\n",
    "\n",
    "\"\"\" for distance in distances:\n",
    "    for angle in angles:\n",
    "        columns = [column for column in X_test.columns if f\"ang_{angle}_dist_{distance}\" in column]\n",
    "        X_train_filtered = X_train.loc[::, columns]\n",
    "        X_test_filtered = X_test.loc[::, columns]\n",
    "\n",
    "        boosted_tree_model = GradientBoostingClassifier(learning_rate=0.1, max_depth=3, n_estimators=100)\n",
    "        \n",
    "        # boosted_tree_model.fit(X_train_filtered, y_train)\n",
    "        # predict = boosted_tree_model.predict(X_test_filtered)\n",
    "        # acurracy = accuracy_score(y_test, predict) * 100\n",
    "        acurracy = (cross_val_score(boosted_tree_model, X_test_filtered, y_test, cv=kf).mean()) * 100\n",
    "        \n",
    "        # predicts[\"GradientBoostingClassifier\"][f\"ang_{angle}_dist_{distance}\"] = predict\n",
    "        scores[\"GradientBoostingClassifier\"][f\"ang_{angle}_dist_{distance}\"] = {\"accuracy_score\": acurracy} \"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' for distance in distances:\\n    for angle in angles:\\n        columns = [column for column in X_test.columns if f\"ang_{angle}_dist_{distance}\" in column ]\\n        X_train_filtered = X_train.loc[::, columns]\\n        X_test_filtered = X_test.loc[::, columns]\\n\\n        #mlp = create_model(X_test_filtered.shape[1])\\n        #mlp.fit(X_train_filtered, y_train, epochs=100, batch_size=5, verbose=0)\\n        #predict = mlp.predict(X_test_filtered)\\n        \\n        #predict = (predict > threshold).astype(int) # Transformar as saídas em rótulos\\n        #acurracy = accuracy_score(y_test, predict) * 100\\n        acurracy = evaluate_mlp_model(create_mlp_model(X_test_filtered.shape[1]),\\n                              X_test_filtered, y_test, 5, 100, 5)\\n\\n        #predicts[\"MultilayerPerceptron\"][f\"ang_{angle}_dist_{distance}\"] = predict\\n        scores[\"MultilayerPerceptron\"][f\"ang_{angle}_dist_{distance}\"] = { \"accuracy_score\": acurracy } '"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Treina com todos os angulos e distancias\n",
    "mlp = create_mlp_model(X_test.shape[1])\n",
    "mlp.fit(X_train, y_train, epochs=100, batch_size=5, verbose=0)\n",
    "predict = mlp.predict(X_test)\n",
    "\n",
    "predict = (predict > threshold).astype(int) # Transformar as saídas em rótulos\n",
    "\"\"\" acurracy = evaluate_mlp_model(create_mlp_model(X_test.shape[1]),\n",
    "                              X_test, y_test, 5, 100, 5) \"\"\"\n",
    "\n",
    "# predicts[\"MultilayerPerceptron\"] = {\"all\": predict}\n",
    "scores[\"MultilayerPerceptron\"] = {\"all\": {\"accuracy_score\": acurracy}}\n",
    "\n",
    "\"\"\" for distance in distances:\n",
    "    for angle in angles:\n",
    "        columns = [column for column in X_test.columns if f\"ang_{angle}_dist_{distance}\" in column ]\n",
    "        X_train_filtered = X_train.loc[::, columns]\n",
    "        X_test_filtered = X_test.loc[::, columns]\n",
    "\n",
    "        #mlp = create_model(X_test_filtered.shape[1])\n",
    "        #mlp.fit(X_train_filtered, y_train, epochs=100, batch_size=5, verbose=0)\n",
    "        #predict = mlp.predict(X_test_filtered)\n",
    "        \n",
    "        #predict = (predict > threshold).astype(int) # Transformar as saídas em rótulos\n",
    "        #acurracy = accuracy_score(y_test, predict) * 100\n",
    "        acurracy = evaluate_mlp_model(create_mlp_model(X_test_filtered.shape[1]),\n",
    "                              X_test_filtered, y_test, 5, 100, 5)\n",
    "\n",
    "        #predicts[\"MultilayerPerceptron\"][f\"ang_{angle}_dist_{distance}\"] = predict\n",
    "        scores[\"MultilayerPerceptron\"][f\"ang_{angle}_dist_{distance}\"] = { \"accuracy_score\": acurracy } \"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliação dos modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acurácia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN</td>\n",
       "      <td>45.945946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>59.459459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM</td>\n",
       "      <td>48.648649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Boosted Tree</td>\n",
       "      <td>62.162162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Multilayer Perceptron</td>\n",
       "      <td>62.162162</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   model        all\n",
       "0                    KNN  45.945946\n",
       "1          Random Forest  59.459459\n",
       "2                    SVM  48.648649\n",
       "3           Boosted Tree  62.162162\n",
       "4  Multilayer Perceptron  62.162162"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_knn = pd.DataFrame(scores[\"KNeighborsClassifier\"])\n",
    "scores_random_forest = pd.DataFrame(scores[\"RandomForestClassifier\"])\n",
    "scores_svm = pd.DataFrame(scores[\"SVM\"])\n",
    "scores_boosted_tree = pd.DataFrame(scores[\"GradientBoostingClassifier\"])\n",
    "scores_perceptron = pd.DataFrame(scores[\"MultilayerPerceptron\"])\n",
    "\n",
    "merged_df = pd.concat([scores_knn, scores_random_forest, scores_svm, scores_boosted_tree,\n",
    "                       scores_perceptron], axis=0).reset_index(drop=True)\n",
    "merged_df['model'] = ['KNN', 'Random Forest', 'SVM', 'Boosted Tree', 'Multilayer Perceptron']\n",
    "\n",
    "columns = merged_df.columns.tolist()\n",
    "columns.remove('model')\n",
    "\n",
    "merged_df = merged_df[['model', *columns]]\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matriz de confusão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' model = create_mlp_model(X_test_INBREAST.shape[1])\\n\\n# Divisão em feature e labels\\nX_INBREAST, y_INBREAST = (breast_cancer_INBREAST.drop(\"pathology\", axis=1), breast_cancer_INBREAST[\"pathology\"])\\n\\n# Balanceamento\\nnm = NearMiss(version=1)\\nX_INBREAST, y_INBREAST = nm.fit_resample(X_INBREAST, y_INBREAST)\\n\\n# Divisão em treino e teste\\nX_train_INBREAST, X_test_INBREAST, y_train_INBREAST, y_test_INBREAST = train_test_split(X_INBREAST, y_INBREAST, test_size=0.30)\\n\\n# Padronização\\ncolumns = X_INBREAST.columns\\nscaler = StandardScaler()\\nX_train_INBREAST = pd.DataFrame(scaler.fit_transform(X_train_INBREAST), columns=columns)\\nX_test_INBREAST = pd.DataFrame(scaler.transform(X_test_INBREAST), columns=columns)\\n\\n# Tratamento dos rótulos categóricos\\ny_train_INBREAST = y_train_INBREAST.map({\"BENIGN\": 0, \"MALIGNANT\": 1})\\ny_test_INBREAST = y_test_INBREAST.map({\"BENIGN\": 0, \"MALIGNANT\": 1})\\n\\n# Treinamento e previsão\\nmodel.fit(X_train_INBREAST, y_train_INBREAST, epochs=100, batch_size=5, verbose=0)\\npredict = model.predict(X_test_INBREAST)\\n\\ntrue_positive, false_positive = [], []\\ntrue_negative, false_negative = [], []\\n\\nfor i in range(len(predict)):\\n    if predict[i] > 0.5:\\n        if y_test_INBREAST.iloc[i] == 1:\\n            true_positive.append(y_test_INBREAST.index[i])\\n        else:\\n            false_positive.append(y_test_INBREAST.index[i])\\n    else:\\n        if y_test_INBREAST.iloc[i] == 0:\\n            true_negative.append(y_test_INBREAST.index[i])\\n        else:\\n            false_negative.append(y_test_INBREAST.index[i]) '"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" model = create_mlp_model(X_test_INBREAST.shape[1])\n",
    "\n",
    "# Divisão em feature e labels\n",
    "X_INBREAST, y_INBREAST = (breast_cancer_INBREAST.drop(\"pathology\", axis=1), breast_cancer_INBREAST[\"pathology\"])\n",
    "\n",
    "# Balanceamento\n",
    "nm = NearMiss(version=1)\n",
    "X_INBREAST, y_INBREAST = nm.fit_resample(X_INBREAST, y_INBREAST)\n",
    "\n",
    "# Divisão em treino e teste\n",
    "X_train_INBREAST, X_test_INBREAST, y_train_INBREAST, y_test_INBREAST = train_test_split(X_INBREAST, y_INBREAST, test_size=0.30)\n",
    "\n",
    "# Padronização\n",
    "columns = X_INBREAST.columns\n",
    "scaler = StandardScaler()\n",
    "X_train_INBREAST = pd.DataFrame(scaler.fit_transform(X_train_INBREAST), columns=columns)\n",
    "X_test_INBREAST = pd.DataFrame(scaler.transform(X_test_INBREAST), columns=columns)\n",
    "\n",
    "# Tratamento dos rótulos categóricos\n",
    "y_train_INBREAST = y_train_INBREAST.map({\"BENIGN\": 0, \"MALIGNANT\": 1})\n",
    "y_test_INBREAST = y_test_INBREAST.map({\"BENIGN\": 0, \"MALIGNANT\": 1})\n",
    "\n",
    "# Treinamento e previsão\n",
    "model.fit(X_train_INBREAST, y_train_INBREAST, epochs=100, batch_size=5, verbose=0)\n",
    "predict = model.predict(X_test_INBREAST)\n",
    "\n",
    "true_positive, false_positive = [], []\n",
    "true_negative, false_negative = [], []\n",
    "\n",
    "for i in range(len(predict)):\n",
    "    if predict[i] > 0.5:\n",
    "        if y_test_INBREAST.iloc[i] == 1:\n",
    "            true_positive.append(y_test_INBREAST.index[i])\n",
    "        else:\n",
    "            false_positive.append(y_test_INBREAST.index[i])\n",
    "    else:\n",
    "        if y_test_INBREAST.iloc[i] == 0:\n",
    "            true_negative.append(y_test_INBREAST.index[i])\n",
    "        else:\n",
    "            false_negative.append(y_test_INBREAST.index[i]) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' metadata_INBREAST = load_json(\"extracted_metadata_INBREAST\", \"../../outputs/mamografia/extracted_metadata\")\\nmetadata_INBREAST\\n\\nlabels = [\\'Verdadeiro Positivo\\', \\'Falso Positivo\\', \\'Verdadeiro Negativo\\', \\'Falso Negativo\\']\\nindexes = [(0, 0), (0, 1), (1, 0), (1, 1)]\\niterables = [true_positive, false_positive, true_negative, false_negative]\\nprint(len(true_positive), len(false_positive), len(true_negative), len(false_negative)) '"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" metadata_INBREAST = load_json(\"extracted_metadata_INBREAST\", \"../../outputs/mamografia/extracted_metadata\")\n",
    "metadata_INBREAST\n",
    "\n",
    "labels = ['Verdadeiro Positivo', 'Falso Positivo', 'Verdadeiro Negativo', 'Falso Negativo']\n",
    "indexes = [(0, 0), (0, 1), (1, 0), (1, 1)]\n",
    "iterables = [true_positive, false_positive, true_negative, false_negative]\n",
    "print(len(true_positive), len(false_positive), len(true_negative), len(false_negative)) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' # Tamanho em polegadas (1 polegada = 2.54 cm)\\nlargura_cm = 120\\naltura_cm = 90\\ndpi = 300  # Resolução em pontos por polegada (recomendada para impressão)\\n\\n# Converta as dimensões de cm para polegadas\\nlargura_in = largura_cm / 2.54\\naltura_in = altura_cm / 2.54\\n\\nfig, ax = plt.subplots(2, 2, fig_size=(largura_in, altura_in), dpi=dpi)\\nplt.subplots_adjust(left=0.20, right=0.80, top=0.80, bottom=0.20, wspace=0.2, hspace=0.15)\\nid_iters = [7, 1, 0, 0]\\n\\nfor label, index, iterable, id_iter in zip(labels, indexes, iterables, id_iters):\\n    img_index = iterable[id_iter]\\n    ax[index[0], index[1]].imshow(dcmread(metadata_INBREAST[img_index][\\'metadata_csv\\'][\\'image_path\\']).pixel_array,\\n                                  cmap=plt.cm.bone)\\n    ax[index[0], index[1]].set_title(f\"{label}\", family=\\'Times New Roman\\', size=14)\\n    ax[index[0], index[1]].set_xticks([])\\n    ax[index[0], index[1]].axis(\\'off\\') '"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" # Tamanho em polegadas (1 polegada = 2.54 cm)\n",
    "largura_cm = 120\n",
    "altura_cm = 90\n",
    "dpi = 300  # Resolução em pontos por polegada (recomendada para impressão)\n",
    "\n",
    "# Converta as dimensões de cm para polegadas\n",
    "largura_in = largura_cm / 2.54\n",
    "altura_in = altura_cm / 2.54\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, fig_size=(largura_in, altura_in), dpi=dpi)\n",
    "plt.subplots_adjust(left=0.20, right=0.80, top=0.80, bottom=0.20, wspace=0.2, hspace=0.15)\n",
    "id_iters = [7, 1, 0, 0]\n",
    "\n",
    "for label, index, iterable, id_iter in zip(labels, indexes, iterables, id_iters):\n",
    "    img_index = iterable[id_iter]\n",
    "    ax[index[0], index[1]].imshow(dcmread(metadata_INBREAST[img_index]['metadata_csv']['image_path']).pixel_array,\n",
    "                                  cmap=plt.cm.bone)\n",
    "    ax[index[0], index[1]].set_title(f\"{label}\", family='Times New Roman', size=14)\n",
    "    ax[index[0], index[1]].set_xticks([])\n",
    "    ax[index[0], index[1]].axis('off') \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' metadata_INBREAST = load_json(\"extracted_metadata_INBREAST\", \"../../outputs/mamografia/extracted_metadata\")\\nnegative = [metadata for metadata in metadata_INBREAST if \\n            metadata[\\'metadata_csv\\'][\\'bi-rads\\'] not in [\\'4c\\', \\'5\\', \\'6\\']]\\npositive = [metadata for metadata in metadata_INBREAST if \\n            metadata[\\'metadata_csv\\'][\\'bi-rads\\'] in [\\'4c\\', \\'5\\', \\'6\\']]\\n\\nimg1 = dcmread(negative[72][\\'metadata_csv\\'][\\'image_path\\']).pixel_array\\nimg2 = dcmread(positive[4][\\'metadata_csv\\'][\\'image_path\\']).pixel_array\\nimg3 = dcmread(negative[10][\\'metadata_csv\\'][\\'image_path\\']).pixel_array\\nimg4 = dcmread(negative[94][\\'metadata_csv\\'][\\'image_path\\']).pixel_array\\n '"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" metadata_INBREAST = load_json(\"extracted_metadata_INBREAST\", \"../../outputs/mamografia/extracted_metadata\")\n",
    "negative = [metadata for metadata in metadata_INBREAST if \n",
    "            metadata['metadata_csv']['bi-rads'] not in ['4c', '5', '6']]\n",
    "positive = [metadata for metadata in metadata_INBREAST if \n",
    "            metadata['metadata_csv']['bi-rads'] in ['4c', '5', '6']]\n",
    "\n",
    "img1 = dcmread(negative[72]['metadata_csv']['image_path']).pixel_array\n",
    "img2 = dcmread(positive[4]['metadata_csv']['image_path']).pixel_array\n",
    "img3 = dcmread(negative[10]['metadata_csv']['image_path']).pixel_array\n",
    "img4 = dcmread(negative[94]['metadata_csv']['image_path']).pixel_array\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\nlabels = [\\'Verdadeiro Positivo\\', \\'Falso Positivo\\', \\'Verdadeiro Negativo\\', \\'Falso Negativo\\']\\nindexes = [(0, 0), (0, 1), (1, 0), (1, 1)]\\nimgs = [img1, img2, img3, img4]\\nids = [72, 4, 10, 94]\\n\\n# Tamanho em polegadas (1 polegada = 2.54 cm)\\nlargura_cm = 120\\naltura_cm = 90\\ndpi = 300  # Resolução em pontos por polegada (recomendada para impressão)\\n\\n# Converta as dimensões de cm para polegadas\\nlargura_in = largura_cm / 2.54\\naltura_in = altura_cm / 2.54\\n\\nfig, ax = plt.subplots(2, 2, figsize=(largura_in, altura_in), dpi=dpi)\\n#plt.subplots_adjust(left=0.20, right=0.80, top=0.80, bottom=0.20, wspace=0.2, hspace=0.15)\\nplt.subplots_adjust(wspace=-0.4, hspace=0.15, right=0.8, left=0.2, top=0.8, bottom=0.2)\\n\\nfor label, index, img in zip(labels, indexes, imgs):\\n    ax[index[0], index[1]].imshow(img, cmap=plt.cm.bone)\\n    ax[index[0], index[1]].set_title(f\"{label}\", family=\\'Times New Roman\\', fontsize=60, pad=20)\\n    ax[index[0], index[1]].set_xticks([])\\n    ax[index[0], index[1]].axis(\\'off\\')\\n '"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" \n",
    "labels = ['Verdadeiro Positivo', 'Falso Positivo', 'Verdadeiro Negativo', 'Falso Negativo']\n",
    "indexes = [(0, 0), (0, 1), (1, 0), (1, 1)]\n",
    "imgs = [img1, img2, img3, img4]\n",
    "ids = [72, 4, 10, 94]\n",
    "\n",
    "# Tamanho em polegadas (1 polegada = 2.54 cm)\n",
    "largura_cm = 120\n",
    "altura_cm = 90\n",
    "dpi = 300  # Resolução em pontos por polegada (recomendada para impressão)\n",
    "\n",
    "# Converta as dimensões de cm para polegadas\n",
    "largura_in = largura_cm / 2.54\n",
    "altura_in = altura_cm / 2.54\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(largura_in, altura_in), dpi=dpi)\n",
    "#plt.subplots_adjust(left=0.20, right=0.80, top=0.80, bottom=0.20, wspace=0.2, hspace=0.15)\n",
    "plt.subplots_adjust(wspace=-0.4, hspace=0.15, right=0.8, left=0.2, top=0.8, bottom=0.2)\n",
    "\n",
    "for label, index, img in zip(labels, indexes, imgs):\n",
    "    ax[index[0], index[1]].imshow(img, cmap=plt.cm.bone)\n",
    "    ax[index[0], index[1]].set_title(f\"{label}\", family='Times New Roman', fontsize=60, pad=20)\n",
    "    ax[index[0], index[1]].set_xticks([])\n",
    "    ax[index[0], index[1]].axis('off')\n",
    " \"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "radiomica",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
