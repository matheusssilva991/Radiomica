{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from pydicom import dcmread\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Catalogar dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções Uteis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregar e salvar em Json e pré processar path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_path(path: str) -> str:\n",
    "    path = path.split(\"/\")\n",
    "    path = path[0]\n",
    "    \n",
    "    return path\n",
    "\n",
    "def load_json(object_name: str) -> None | object:\n",
    "    path = os.path.abspath(\"catalogar_dicom_imagens.ipynb\")\n",
    "    path = \"/\".join(path.split(\"\\\\\")[:-2:])\n",
    "    path = path + f\"/metadata/metadata_csv_and_dicom/{object_name}.json\"\n",
    "    try:\n",
    "        with open(path, 'r') as json_file:\n",
    "            return json.load(json_file)  \n",
    "    except json.decoder.JSONDecodeError:\n",
    "        return None\n",
    "    except FileNotFoundError:\n",
    "        with open(path, 'w', encoding='utf-8') as json_file:\n",
    "            return None\n",
    "        \n",
    "def save_json(object_name: str, list_metadata: list) -> None:\n",
    "    path = f\"../metadata/metadata_csv_and_dicom/{object_name}.json\"\n",
    "    with open(path, 'w', encoding='utf-8') as json_file:\n",
    "        json.dump(list_metadata, json_file, ensure_ascii=False, indent=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### construtoras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dicom_meta(dicom_file: object) -> dict:\n",
    "    dictionary = {}\n",
    "\n",
    "    for data_element in dicom_file:\n",
    "        if data_element.value == \"\" or data_element.description() in [\"Pixel Array\", \"Pixel Data\"]:\n",
    "            continue\n",
    "    \n",
    "        tag = data_element.tag\n",
    "        tag_name = data_element.description()\n",
    "        tag_name = tag_name.replace(\" \", \"_\").lower()\n",
    "        \n",
    "        if tag_name in [\"patient's_name\", \"referring_physician's_name\"]:\n",
    "            value = \"^\".join(data_element.value.components)\n",
    "        else:\n",
    "            value = data_element.value\n",
    "            \n",
    "        if isinstance(value, bytes):\n",
    "            value = value.decode(\"utf-8\")\n",
    "        \n",
    "        dictionary[f\"{tag_name} {tag}\"] = value\n",
    "    \n",
    "    return dictionary\n",
    "\n",
    "def study_factory(study_name: str, metadata_csv: dict, metadata_dicom_files: list) -> dict:\n",
    "    return {'study_name': study_name,\n",
    "            'metadata_csv': metadata_csv,\n",
    "            'metadata_dicom_files':metadata_dicom_files\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pegar Metadados em csv e dicom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_study_metadata(paths: dict, metadata_csv: object, indice: int) -> dict:\n",
    "    # Pega metadados no dataframe\n",
    "    dic_meta_in_csv = {}  \n",
    "    \n",
    "    for col in metadata_csv.iloc[::, :11:].columns.tolist():\n",
    "        if isinstance(metadata_csv[col][indice], np.integer):\n",
    "            dic_meta_in_csv[col] = int(metadata_csv[col][indice])\n",
    "        elif pd.isna(metadata_csv[col][indice]):\n",
    "            dic_meta_in_csv[col] = \"Nan\"\n",
    "        else:\n",
    "            dic_meta_in_csv[col] = metadata_csv[col][indice]\n",
    "    \n",
    "    # Pega metadados no objeto dicom\n",
    "    metadata_dicom_files = {\"original\": [], \"cropped\": []}\n",
    "    #metadata_dicom_files = {\"original\": [], \"cropped\": [], \"roi\": []}\n",
    "    \n",
    "    for key, path in paths.items():\n",
    "        path_exam_files = f\"D:/mathe/Documents/BancoDados_IC/CBIS-DDSM/{path}/\"\n",
    "        directory = Path(path_exam_files)\n",
    "        paths_dicom_images = list(directory.rglob(\"*.dcm*\"))\n",
    "        \n",
    "        #Adicionar path da imagem no metadados do csv\n",
    "        dic_meta_in_csv[f'{key}_image_path'] = str(paths_dicom_images[0]).replace(\"\\\\\", \"/\").split(\"/\")\n",
    "        dic_meta_in_csv[f'{key}_image_path'].pop() # Retira o nome do arquivo Dicom do Path\n",
    "        dic_meta_in_csv[f'{key}_image_path'] = \"/\".join(dic_meta_in_csv[f'{key}_image_path'])\n",
    "        \n",
    "        for path_dicom in paths_dicom_images:\n",
    "            dicom_file = dcmread(path_dicom)\n",
    "            metadata_dicom_files[key].append(get_dicom_meta(dicom_file))\n",
    "    \n",
    "    return study_factory(paths['original'], dic_meta_in_csv, metadata_dicom_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salvar metadados arquivos Json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_files = ['calc_case_description_test_set',\n",
    "             'mass_case_description_train_set',\n",
    "             'calc_case_description_train_set',\n",
    "             'mass_case_description_test_set']\n",
    "\n",
    "for current_meta in metadata_files:\n",
    "    df = pd.read_csv(f\"../metadata//{current_meta}.csv\")\n",
    "    \n",
    "    studies = []\n",
    "    for i in range(df.shape[0]):\n",
    "        original_image_path = df.iloc[i][11]\n",
    "        cropped_images_path = df.iloc[i][12]\n",
    "        #roi_image_path = df.iloc[i][13]\n",
    "        \n",
    "        original_image_path = preprocessing_path(original_image_path)\n",
    "        cropped_images_path = preprocessing_path(cropped_images_path)\n",
    "        #roi_image_path = preprocessing_path(roi_image_path)\n",
    "        \n",
    "        metadata = df.iloc[::, :11:]\n",
    "        all_image_path = {\"original\": original_image_path, \"cropped\":cropped_images_path}\n",
    "        #all_image_path = {\"original\": original_image_path, \"cropped\":cropped_images_path, \"roi\": roi_image_path}\n",
    "        \n",
    "        studies.append(get_study_metadata(all_image_path, metadata, i))\n",
    "    save_json(current_meta, studies)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('prov')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "72b0e7aef17bfaf12a24a38efe1b5729927abea9daa7ebf89509f441d033e89a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
